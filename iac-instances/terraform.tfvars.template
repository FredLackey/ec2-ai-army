# AI Army EC2 Instances Configuration
# Generated by create-tfvars-instances.sh

# AWS Configuration
aws_region  = "{{AWS_REGION}}"
aws_profile = "{{AWS_PROFILE}}"

# VPC Configuration
vpc_id    = "{{VPC_ID}}"
subnet_id = "{{SUBNET_ID}}"

# Instance Configuration
instance_count = {{INSTANCE_COUNT}}
instance_type  = "{{INSTANCE_TYPE}}"

# AMI Configuration
# Ubuntu AMI ID - use find-ubuntu-amis.sh to find the latest
ami_id = "{{AMI_ID}}"

# Instance naming
instance_name_prefix = "{{INSTANCE_NAME_PREFIX}}"
environment          = "{{ENVIRONMENT}}"

# Monitoring Configuration
# Set to false by default to save costs
# CloudWatch detailed monitoring costs ~$2.10/month per instance
enable_monitoring = {{ENABLE_MONITORING}}

# SSH Key Configuration
# The prefix for the SSH key pair name
# This will be generated if it doesn't exist
key_name_prefix = "ai-army"

# Security Configuration
# Security group name
security_group_name = "ai-army-sg"

# Allowed CIDR blocks for SSH access
allowed_cidr_blocks = ["{{TRUSTED_IP}}"]

# Storage Configuration
# Root volume configuration
root_volume_size = {{ROOT_VOLUME_SIZE}}
root_volume_type = "{{ROOT_VOLUME_TYPE}}"


# ===================================
# HOW TO USE THIS FILE:
# ===================================
# 1. This file is automatically generated by create-tfvars-instances.sh
#    Do not edit this template directly
#
# 2. Run the script to generate terraform.tfvars:
#    ./scripts/create-tfvars-instances.sh -p <profile> -r <region> -v <vpc-id> -s <subnet-id> -c <count>
#
# 3. The script will:
#    - Validate your AWS credentials
#    - Verify the VPC and subnet exist
#    - Find the latest Ubuntu AMI (or use your specified AMI)
#    - Generate SSH keys if needed
#    - Create the terraform.tfvars file
#
# 4. After generation, you can:
#    terraform init
#    terraform plan
#    terraform apply
#
# IMPORTANT: terraform.tfvars is gitignored to protect sensitive information

# ===================================
# INSTANCE SIZING GUIDE:
# ===================================
# Common instance types for AI workloads:
# - t3.micro:   1 vCPU,  1 GB RAM  (~$7.50/month)  - Testing only
# - t3.small:   2 vCPU,  2 GB RAM  (~$15/month)    - Light workloads
# - t3.medium:  2 vCPU,  4 GB RAM  (~$30/month)    - Development
# - t3.large:   2 vCPU,  8 GB RAM  (~$60/month)    - Small models
# - t3.xlarge:  4 vCPU, 16 GB RAM  (~$120/month)   - Medium models
# - g4dn.xlarge: 4 vCPU, 16 GB RAM, GPU (~$380/month) - GPU workloads
#
# Storage costs:
# - gp3: $0.08/GB/month (default)
# - gp2: $0.10/GB/month (legacy)
# - io1/io2: $0.125/GB/month + IOPS charges

# ===================================
# COST OPTIMIZATION TIPS:
# ===================================
# 1. Use Spot Instances for non-critical workloads (up to 90% savings)
# 2. Use Reserved Instances for long-term workloads (up to 72% savings)
# 3. Disable detailed monitoring if not needed (saves $2.10/month per instance)
# 4. Use S3 for data storage instead of large EBS volumes
# 5. Stop instances when not in use (you still pay for EBS volumes)